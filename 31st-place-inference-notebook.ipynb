{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44149fe",
   "metadata": {
    "papermill": {
     "duration": 0.008859,
     "end_time": "2023-11-16T09:41:19.818023",
     "exception": false,
     "start_time": "2023-11-16T09:41:19.809164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Team AudioAlchemists - Inference Notebook - Wav2Vec2\n",
    "\n",
    "- Team Members: `Syed Mostofa Monsur Dipto` | `Sakib Chowdhury` | `Md Boktiar Mahbub Murad` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affddb3",
   "metadata": {
    "papermill": {
     "duration": 0.007893,
     "end_time": "2023-11-16T09:41:19.833853",
     "exception": false,
     "start_time": "2023-11-16T09:41:19.825960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c639d",
   "metadata": {
    "papermill": {
     "duration": 0.007263,
     "end_time": "2023-11-16T09:41:19.848887",
     "exception": false,
     "start_time": "2023-11-16T09:41:19.841624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. [Model weights](https://www.kaggle.com/datasets/mbmmurad/checkpoint-450000ind2-aug)\n",
    "2. [Language Model](https://www.kaggle.com/datasets/mbmmurad/final-lm-benai/)\n",
    "3. [Dependencies](https://www.kaggle.com/datasets/shahruk10/csefest2022dlsprintdeps/versions/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10dab64",
   "metadata": {
    "papermill": {
     "duration": 0.00927,
     "end_time": "2023-11-16T09:41:19.866553",
     "exception": false,
     "start_time": "2023-11-16T09:41:19.857283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f55062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:41:19.886118Z",
     "iopub.status.busy": "2023-11-16T09:41:19.885507Z",
     "iopub.status.idle": "2023-11-16T09:41:20.838854Z",
     "shell.execute_reply": "2023-11-16T09:41:20.837881Z"
    },
    "papermill": {
     "duration": 0.966422,
     "end_time": "2023-11-16T09:41:20.841508",
     "exception": false,
     "start_time": "2023-11-16T09:41:19.875086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33dcac35",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-16T09:41:20.858418Z",
     "iopub.status.busy": "2023-11-16T09:41:20.858042Z",
     "iopub.status.idle": "2023-11-16T09:41:22.618322Z",
     "shell.execute_reply": "2023-11-16T09:41:22.617220Z"
    },
    "papermill": {
     "duration": 1.771641,
     "end_time": "2023-11-16T09:41:22.620848",
     "exception": false,
     "start_time": "2023-11-16T09:41:20.849207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/csefest2022dlsprintdeps ./deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2196ad43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:41:22.637983Z",
     "iopub.status.busy": "2023-11-16T09:41:22.637649Z",
     "iopub.status.idle": "2023-11-16T09:46:27.429116Z",
     "shell.execute_reply": "2023-11-16T09:46:27.427562Z"
    },
    "papermill": {
     "duration": 304.803141,
     "end_time": "2023-11-16T09:46:27.431750",
     "exception": false,
     "start_time": "2023-11-16T09:41:22.628609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./deps/pygtrie-2.5.0/pygtrie-2.5.0\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pygtrie\r\n",
      "  Building wheel for pygtrie (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pygtrie: filename=pygtrie-2.5.0-py3-none-any.whl size=20944 sha256=7e720f66fd9b13fcda075fe994ae395348c735cc9d844627401abdaf3cb5d842\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/97/76/3c/04d3f51356d58b1de1abd51542fec46dec27fc231e6c73de07\r\n",
      "Successfully built pygtrie\r\n",
      "Installing collected packages: pygtrie\r\n",
      "Successfully installed pygtrie-2.5.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/exceptiongroup-1.0.0rc8-py3-none-any.whl\r\n",
      "Installing collected packages: exceptiongroup\r\n",
      "Successfully installed exceptiongroup-1.0.0rc8\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/hypothesis-6.54.4-py3-none-any.whl\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis==6.54.4) (21.4.0)\r\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis==6.54.4) (2.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.7/site-packages (from hypothesis==6.54.4) (1.0.0rc8)\r\n",
      "Installing collected packages: hypothesis\r\n",
      "Successfully installed hypothesis-6.54.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/pyctcdecode-0.4.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: hypothesis<7,>=6.14 in /opt/conda/lib/python3.7/site-packages (from pyctcdecode==0.4.0) (6.54.4)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from pyctcdecode==0.4.0) (1.21.6)\r\n",
      "Requirement already satisfied: pygtrie<3.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from pyctcdecode==0.4.0) (2.5.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.7/site-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (1.0.0rc8)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (21.4.0)\r\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (2.4.0)\r\n",
      "Installing collected packages: pyctcdecode\r\n",
      "Successfully installed pyctcdecode-0.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/pypi-kenlm-0.1.20220713/pypi-kenlm-0.1.20220713\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: pypi-kenlm\r\n",
      "  Building wheel for pypi-kenlm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pypi-kenlm: filename=pypi_kenlm-0.1.20220713-cp37-cp37m-linux_x86_64.whl size=2963520 sha256=87bdae48d44d83dd30b60d3f582c3ea617e88a8669aafa79c65967818fe113df\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/36/70/93339faca68c8ec74b3b2ef56fa8cbe162c81ced6a5f12cbc3\r\n",
      "Successfully built pypi-kenlm\r\n",
      "Installing collected packages: pypi-kenlm\r\n",
      "Successfully installed pypi-kenlm-0.1.20220713\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/bnunicodenormalizer-0.0.23/bnunicodenormalizer-0.0.23\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: bnunicodenormalizer\r\n",
      "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.0.23-py3-none-any.whl size=17591 sha256=93785355e9ae9bed7e780b8211fb62bfaa350d049a610c22f8b9b9c67c80970f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/91/b8/aeef9cf96411d54101500af00f37845e5566f56c8f18e85ce5\r\n",
      "Successfully built bnunicodenormalizer\r\n",
      "Installing collected packages: bnunicodenormalizer\r\n",
      "Successfully installed bnunicodenormalizer-0.0.23\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/python-Levenshtein-0.12.2/python-Levenshtein-0.12.2\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from python-Levenshtein==0.12.2) (59.8.0)\r\n",
      "Building wheels for collected packages: python-Levenshtein\r\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=182883 sha256=922da84462433b797c975b2d309700646daafe7dc1e4e6f0a26e3d97e5c16b01\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/f3/6f/5f6f8ca0aa1ac1a2bd42bfa25f3556a954ad702449b40f58d6\r\n",
      "Successfully built python-Levenshtein\r\n",
      "Installing collected packages: python-Levenshtein\r\n",
      "  Attempting uninstall: python-Levenshtein\r\n",
      "    Found existing installation: python-Levenshtein 0.12.2\r\n",
      "    Uninstalling python-Levenshtein-0.12.2:\r\n",
      "      Successfully uninstalled python-Levenshtein-0.12.2\r\n",
      "Successfully installed python-Levenshtein-0.12.2\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0mProcessing ./deps/jiwer-2.3.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: python-Levenshtein==0.12.2 in /opt/conda/lib/python3.7/site-packages (from jiwer==2.3.0) (0.12.2)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from python-Levenshtein==0.12.2->jiwer==2.3.0) (59.8.0)\r\n",
      "Installing collected packages: jiwer\r\n",
      "Successfully installed jiwer-2.3.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ./deps/pygtrie-2.5.0/pygtrie-2.5.0\n",
    "!pip install ./deps/exceptiongroup-1.0.0rc8-py3-none-any.whl\n",
    "!pip install ./deps/hypothesis-6.54.4-py3-none-any.whl\n",
    "!pip install ./deps/pyctcdecode-0.4.0-py2.py3-none-any.whl\n",
    "!pip install ./deps/pypi-kenlm-0.1.20220713/pypi-kenlm-0.1.20220713\n",
    "!pip install ./deps/bnunicodenormalizer-0.0.23/bnunicodenormalizer-0.0.23\n",
    "!pip install ./deps/python-Levenshtein-0.12.2/python-Levenshtein-0.12.2\n",
    "!pip install ./deps/jiwer-2.3.0-py3-none-any.whl\n",
    "\n",
    "!chmod +x ./deps/kenlm/kenlm/bin/lmplz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131bf5a",
   "metadata": {
    "papermill": {
     "duration": 0.0141,
     "end_time": "2023-11-16T09:46:27.460638",
     "exception": false,
     "start_time": "2023-11-16T09:46:27.446538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f67fbd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:46:27.490792Z",
     "iopub.status.busy": "2023-11-16T09:46:27.490459Z",
     "iopub.status.idle": "2023-11-16T09:46:31.288283Z",
     "shell.execute_reply": "2023-11-16T09:46:31.287203Z"
    },
    "papermill": {
     "duration": 3.816107,
     "end_time": "2023-11-16T09:46:31.290896",
     "exception": false,
     "start_time": "2023-11-16T09:46:27.474789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Any, Union\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor\n",
    "from pyctcdecode import build_ctcdecoder\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "\n",
    "import pyctcdecode\n",
    "\n",
    "from bnunicodenormalizer import Normalizer \n",
    "from datasets import load_metric\n",
    "\n",
    "bnorm = Normalizer()\n",
    "wer = load_metric(\"../input/csefest2022dlsprintdeps/metrics/metrics/wer.py\")\n",
    "cer = load_metric(\"../input/csefest2022dlsprintdeps/metrics/metrics/cer.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9d9bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:46:31.323502Z",
     "iopub.status.busy": "2023-11-16T09:46:31.322048Z",
     "iopub.status.idle": "2023-11-16T09:46:31.328510Z",
     "shell.execute_reply": "2023-11-16T09:46:31.327619Z"
    },
    "papermill": {
     "duration": 0.024777,
     "end_time": "2023-11-16T09:46:31.330621",
     "exception": false,
     "start_time": "2023-11-16T09:46:31.305844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocabPath = '/kaggle/input/ckpt-270k/check_de_model/vocab.json'\n",
    "lmPath = \"/kaggle/input/final-lm-benai/5gram.arpa\"\n",
    "ckptPath = \"/kaggle/input/checkpoint-450000ind2-aug\"\n",
    "\n",
    "sampleSubmissionPath = '/kaggle/input/bengaliai-speech/sample_submission.csv'\n",
    "\n",
    "testDataDir = '../input/dlsprint/test_files'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eac05e",
   "metadata": {
    "papermill": {
     "duration": 0.014696,
     "end_time": "2023-11-16T09:46:31.359963",
     "exception": false,
     "start_time": "2023-11-16T09:46:31.345267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abc7d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:46:31.390691Z",
     "iopub.status.busy": "2023-11-16T09:46:31.390299Z",
     "iopub.status.idle": "2023-11-16T09:46:31.414120Z",
     "shell.execute_reply": "2023-11-16T09:46:31.413222Z"
    },
    "papermill": {
     "duration": 0.042047,
     "end_time": "2023-11-16T09:46:31.416589",
     "exception": false,
     "start_time": "2023-11-16T09:46:31.374542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(\"/kaggle/input/ckpt-270k/check_de_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72525c43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:46:31.448561Z",
     "iopub.status.busy": "2023-11-16T09:46:31.447827Z",
     "iopub.status.idle": "2023-11-16T09:49:08.093675Z",
     "shell.execute_reply": "2023-11-16T09:49:08.092787Z"
    },
    "papermill": {
     "duration": 156.66447,
     "end_time": "2023-11-16T09:49:08.096365",
     "exception": false,
     "start_time": "2023-11-16T09:46:31.431895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /kaggle/input/final-lm-benai/5gram.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),\n",
    "    lmPath,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446caf69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:08.127489Z",
     "iopub.status.busy": "2023-11-16T09:49:08.127148Z",
     "iopub.status.idle": "2023-11-16T09:49:23.383611Z",
     "shell.execute_reply": "2023-11-16T09:49:23.382671Z"
    },
    "papermill": {
     "duration": 15.275432,
     "end_time": "2023-11-16T09:49:23.386923",
     "exception": false,
     "start_time": "2023-11-16T09:49:08.111491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (12): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (13): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (14): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (15): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (16): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (17): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (18): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (19): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (20): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (21): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (22): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (23): Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=87, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(vocabPath, 'r', encoding=\"utf-8\") as vocabFile:\n",
    "    vocabc2n = json.load(vocabFile)\n",
    "\n",
    "vocabn2c = { v:k for k,v in vocabc2n.items() }\n",
    "vocab = list(vocabc2n.keys())\n",
    "\n",
    "tokenizer = processor.tokenizer\n",
    "\n",
    "feature_extractor = processor.feature_extractor\n",
    "\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(ckptPath)\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b2b226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:23.418799Z",
     "iopub.status.busy": "2023-11-16T09:49:23.418506Z",
     "iopub.status.idle": "2023-11-16T09:49:23.436845Z",
     "shell.execute_reply": "2023-11-16T09:49:23.435823Z"
    },
    "papermill": {
     "duration": 0.036531,
     "end_time": "2023-11-16T09:49:23.438964",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.402433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(sampleSubmissionPath)\n",
    "test_df['id'] = [ os.path.join(testDataDir, x) for x in test_df['id'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae2821",
   "metadata": {
    "papermill": {
     "duration": 0.015463,
     "end_time": "2023-11-16T09:49:23.469718",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.454255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8afa8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:23.503463Z",
     "iopub.status.busy": "2023-11-16T09:49:23.502800Z",
     "iopub.status.idle": "2023-11-16T09:49:23.517714Z",
     "shell.execute_reply": "2023-11-16T09:49:23.516709Z"
    },
    "papermill": {
     "duration": 0.034218,
     "end_time": "2023-11-16T09:49:23.519804",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.485586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioConverter:\n",
    "    \"\"\"\n",
    "    AudioConverter offers methods to load, transcode and augment\n",
    "    audio data in various ways.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configurations for parameters used in torchaudio's resampling kernel.\n",
    "    resampleFilterParams = {\n",
    "        \"fast\": {  # Fast and less accurate but still MSE = ~2e-5 compared to librosa.\n",
    "            \"lowpass_filter_width\": 16,\n",
    "            \"rolloff\": 0.85,\n",
    "            \"resampling_method\": \"kaiser_window\",\n",
    "            \"beta\": 8.555504641634386,\n",
    "        },\n",
    "        \"best\": { # Twice as slow, and a little bit more accurate.\n",
    "            \"lowpass_filter_width\": 64,\n",
    "            \"rolloff\": 0.9475937167399596,\n",
    "            \"resampling_method\": \"kaiser_window\",\n",
    "            \"beta\": 14.769656459379492,       \n",
    "        },\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sampleRate: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes AudioConverter.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        sampleRate: int\n",
    "            Sampling rate to convert audio to, if required.\n",
    "        \"\"\"\n",
    "        self.sampleRate = sampleRate\n",
    "\n",
    "    @classmethod\n",
    "    def loadAudio(\n",
    "        cls, audioPath: str, sampleRate: int = None, returnTensor: bool = True, resampleType: str = \"fast\",\n",
    "    ) -> Union[torch.Tensor, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Uses torchaudio to load and resample (if necessary) audio files and returns\n",
    "        audio samples as either a numpy.float32 array or a torch.Tensor.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        audioPath: str\n",
    "            Path to audio file file (wav / mp3 / flac).\n",
    "        \n",
    "        sampleRate: int, optional\n",
    "            Sampling rate to convert audio to. If None,\n",
    "            audio is not resampled.\n",
    "        \n",
    "        returnTensor: bool, optional\n",
    "            If True, the audio samples are returned as a torch.Tensor.\n",
    "            Otherwise, the samples are returned as a numpy.float32 array.\n",
    "            \n",
    "        resampleType: str, optional\n",
    "            Either \"fast\" or \"best\" - sets the quality of resampling.\n",
    "            \"best\" is twice as slow as \"fast\" but more accurate. \"fast\"\n",
    "            is still comparable to librosa's resampled output though,\n",
    "            in terms of MSE.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Union[torch.Tensor, np.ndarray]\n",
    "            Audio waveform scaled between +/- 1.0 as either a numpy.float32 array,\n",
    "            or torch.Tensor, with shape (channels, numSamples)\n",
    "        \"\"\"\n",
    "        x, sr = torchaudio.load(audioPath)\n",
    "        if sampleRate is not None or sr != sampleRate:\n",
    "            x = F.resample(x, sr, sampleRate)\n",
    "        \n",
    "        if returnTensor:\n",
    "            return x\n",
    "        \n",
    "        return x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85a21dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:23.553599Z",
     "iopub.status.busy": "2023-11-16T09:49:23.552606Z",
     "iopub.status.idle": "2023-11-16T09:49:23.559050Z",
     "shell.execute_reply": "2023-11-16T09:49:23.557937Z"
    },
    "papermill": {
     "duration": 0.025556,
     "end_time": "2023-11-16T09:49:23.561248",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.535692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(sen):\n",
    "    _words = [ bnorm(word)['normalized']  for word in sen.split() ]\n",
    "    sen = \" \".join([word for word in _words if word is not None]) \n",
    "    sen = sen.replace(\"\\u2047\", \"-\")\n",
    "\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21075051",
   "metadata": {
    "papermill": {
     "duration": 0.015513,
     "end_time": "2023-11-16T09:49:23.592900",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.577387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer on single data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "630fb49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:23.628296Z",
     "iopub.status.busy": "2023-11-16T09:49:23.627372Z",
     "iopub.status.idle": "2023-11-16T09:49:36.970642Z",
     "shell.execute_reply": "2023-11-16T09:49:36.969566Z"
    },
    "papermill": {
     "duration": 13.363931,
     "end_time": "2023-11-16T09:49:36.972819",
     "exception": false,
     "start_time": "2023-11-16T09:49:23.608888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer(audioPath):\n",
    "    wav = AudioConverter.loadAudio(audioPath, sampleRate=16000, returnTensor=False)[0]\n",
    "    inputs = processor(wav, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.float().cuda()).logits\n",
    "   \n",
    "    items = logits.squeeze(0).cpu().numpy()\n",
    "    preds = decoder.decode_beams(items)[0][0]\n",
    "\n",
    "    return normalize(preds) + \"\"\n",
    "\n",
    "\n",
    "infer('/kaggle/input/bengaliai-speech/train_mp3s/0001565ed181.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb7207e",
   "metadata": {
    "papermill": {
     "duration": 0.015347,
     "end_time": "2023-11-16T09:49:37.004120",
     "exception": false,
     "start_time": "2023-11-16T09:49:36.988773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer on a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "725a1b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:37.037469Z",
     "iopub.status.busy": "2023-11-16T09:49:37.036296Z",
     "iopub.status.idle": "2023-11-16T09:49:37.041819Z",
     "shell.execute_reply": "2023-11-16T09:49:37.040854Z"
    },
    "papermill": {
     "duration": 0.024221,
     "end_time": "2023-11-16T09:49:37.044065",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.019844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_infer(audio_paths, batch_size):\n",
    "    preds = [ infer(x) for x in tqdm(audio_paths) ]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099f503",
   "metadata": {
    "papermill": {
     "duration": 0.01522,
     "end_time": "2023-11-16T09:49:37.074727",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.059507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer on a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5008efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:37.107277Z",
     "iopub.status.busy": "2023-11-16T09:49:37.106913Z",
     "iopub.status.idle": "2023-11-16T09:49:37.113006Z",
     "shell.execute_reply": "2023-11-16T09:49:37.112052Z"
    },
    "papermill": {
     "duration": 0.024897,
     "end_time": "2023-11-16T09:49:37.115064",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.090167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def directory_infer(audio_dir):\n",
    "    audio_paths = sorted(glob.glob(audio_dir+'/*'))\n",
    "    preds = batch_infer(audio_paths, 10)\n",
    "    base_paths=[ os.path.basename(p) for p in audio_paths ]\n",
    "    \n",
    "    return pd.DataFrame({'id': base_paths ,'sentence': preds})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9072822",
   "metadata": {
    "papermill": {
     "duration": 0.015526,
     "end_time": "2023-11-16T09:49:37.146002",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.130476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a931b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:37.179182Z",
     "iopub.status.busy": "2023-11-16T09:49:37.178497Z",
     "iopub.status.idle": "2023-11-16T09:49:37.599830Z",
     "shell.execute_reply": "2023-11-16T09:49:37.598886Z"
    },
    "papermill": {
     "duration": 0.440398,
     "end_time": "2023-11-16T09:49:37.602013",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.161615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91e5a8f89bf4383a3821f1bf4b36ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f3dac00655e.mp3</td>\n",
       "      <td>    </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9395e01ad21.mp3</td>\n",
       "      <td>        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bf36ea8b718d.mp3</td>\n",
       "      <td>       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                           sentence\n",
       "0  0f3dac00655e.mp3                              \n",
       "1  a9395e01ad21.mp3          ...\n",
       "2  bf36ea8b718d.mp3         ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = \"/kaggle/input/bengaliai-speech/test_mp3s\"\n",
    "sub = directory_infer(test_dir)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4be0e9f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:37.635438Z",
     "iopub.status.busy": "2023-11-16T09:49:37.635109Z",
     "iopub.status.idle": "2023-11-16T09:49:37.645211Z",
     "shell.execute_reply": "2023-11-16T09:49:37.644329Z"
    },
    "papermill": {
     "duration": 0.028999,
     "end_time": "2023-11-16T09:49:37.647469",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.618470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0f3dac00655e</td>\n",
       "      <td>    </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9395e01ad21</td>\n",
       "      <td>        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bf36ea8b718d</td>\n",
       "      <td>       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           sentence\n",
       "0  0f3dac00655e                              \n",
       "1  a9395e01ad21          ...\n",
       "2  bf36ea8b718d         ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['id'] = sub['id'].apply(lambda x:x.split(\".\")[0])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5292c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T09:49:37.682710Z",
     "iopub.status.busy": "2023-11-16T09:49:37.682092Z",
     "iopub.status.idle": "2023-11-16T09:49:37.688987Z",
     "shell.execute_reply": "2023-11-16T09:49:37.688237Z"
    },
    "papermill": {
     "duration": 0.027533,
     "end_time": "2023-11-16T09:49:37.691005",
     "exception": false,
     "start_time": "2023-11-16T09:49:37.663472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6229904,
     "sourceId": 52324,
     "sourceType": "competition"
    },
    {
     "datasetId": 2446557,
     "sourceId": 4142276,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3729212,
     "sourceId": 6465877,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3767700,
     "sourceId": 6517607,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3873607,
     "sourceId": 6723801,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2433942,
     "isSourceIdPinned": true,
     "sourceId": 6639409,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30214,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 510.096392,
   "end_time": "2023-11-16T09:49:40.829039",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-16T09:41:10.732647",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0ac744de937b47fcae1e5e3033111d1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "31e9d47861e74806b156c947c34ca198": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3f95da6db05d49dea9fe1321e5506ba8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "63a9223eb4e148f1a3a43150d4d80e2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ac744de937b47fcae1e5e3033111d1e",
       "placeholder": "",
       "style": "IPY_MODEL_ef4f3c9ab40d4eb98784e3090736f846",
       "value": " 3/3 [00:00&lt;00:00,  7.74it/s]"
      }
     },
     "a02404568d2c46159a279e62a979d940": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ab9cf00f6e7e47f2bdb474428ac22932": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bef388630be74980bbd389369b7a7d13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f53234d24da24211848c4490d54739d5",
       "placeholder": "",
       "style": "IPY_MODEL_3f95da6db05d49dea9fe1321e5506ba8",
       "value": "100%"
      }
     },
     "e91e5a8f89bf4383a3821f1bf4b36ff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bef388630be74980bbd389369b7a7d13",
        "IPY_MODEL_f714a8a48081414997130278bc50b466",
        "IPY_MODEL_63a9223eb4e148f1a3a43150d4d80e2f"
       ],
       "layout": "IPY_MODEL_a02404568d2c46159a279e62a979d940"
      }
     },
     "ef4f3c9ab40d4eb98784e3090736f846": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f53234d24da24211848c4490d54739d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f714a8a48081414997130278bc50b466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ab9cf00f6e7e47f2bdb474428ac22932",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_31e9d47861e74806b156c947c34ca198",
       "value": 3
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
